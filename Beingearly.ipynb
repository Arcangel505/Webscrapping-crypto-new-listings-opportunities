import requests
from bs4 import BeautifulSoup

res=requests.get("https://www.coingecko.com/en/new-cryptocurrencies")
cres=BeautifulSoup(res.text,'html.parser')
crypto=cres.find_all('a', class_="tw-hidden lg:tw-flex font-bold tw-items-center tw-justify-between")
crypto=crypto[0:10]
#crypto names
crypto_n=[]
for i in crypto:
    var=i.text
    var=var.replace('\n','',2)
    crypto_n.append(var)

#coingecko's pages names
link=[]
for i in crypto:
    var=i["href"]
    var="https://www.coingecko.com"+var
    link.append(var)

#24h volumes
Vol=cres.find_all('td', class_="td-liquidity_score")
Vol=Vol[0:10]
Volume24=[]
for i in Vol:
    var=i.span.text
    Volume24.append((var))

#Whatever advice you'd like to provide can be improved with a bit of data analysis
advice=[]
for i in Volume24:
    var=i.replace("$","")
    var=var.replace(",","")
    var=float(var)
    if var > 20000:
        k="Careful of the listing effect, but maybe interesting for speculation or wait for this to calm down if your fundamental analysis reveals good"
    elif var<1000:
        k="Is this project legitimate?"
    else:
        k="Early stage of the project, check the developper's Git Hub "
    advice.append(k)

#Blockhain
Bc=cres.find_all('div', class_="tw-flex tw-py-1.5 tw-mx-4 tw-justify-between border-bottom text-black")
Bc=Bc[0:10]
Blochain=[]
for i in Bc:
    var=i.span.text
    Blochain.append(var)

#Webpage of the project: we have to scrap the respective coingecko's pages of each project
#We use the list "link" above to go through each pages 
website=[]
for i in link:
    res=requests.get(i)
    cres=BeautifulSoup(res.text,'html.parser')
    url=cres.find("div", class_="tw-flex flex-wrap tw-font-normal")
    url=url.a["href"]
    website.append(url)



#Dev Git Hub: have to be done in two part for the url containing the data is in a loading panel

#1st: get the coin id : to access the true url to scrap the dev git hub
coin_id=[]
for i in link:
    res=requests.get(i)
    cres=BeautifulSoup(res.text,'html.parser')
    dev=cres.find("div",class_="tw-text-4xl tw-font-bold tw-my-2 tw-flex tw-items-center")
    data=dev.span.span["data-coin-id"]
    coin_id.append(data)
coin_id

#2nd: a bit tricky for some projects don't share their git hub so use try except
dev_git=[]
for i in coin_id:
    res=requests.get("https://www.coingecko.com/en/coins/"+i+"/developer_tab")
    cres=BeautifulSoup(res.text,'html.parser')
    try: 
        var=cres.find("a")['href'] 
        
    except:
        var="No link shared"
    dev_git.append(var)

#Make pandas table
import pandas as pd

data=pd.DataFrame({
    "Crypto":crypto_n,
    "Web page":website,
    "coingecks page":link,
    "Blockchain":Blochain,
    "Volume 24H":Volume24,
    "Advice":advice,
    "Dev's GitHub":dev_git
})
